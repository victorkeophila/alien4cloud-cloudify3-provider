from cloudify.decorators import workflow
from cloudify.workflows import ctx
from cloudify.workflows import tasks as workflow_tasks
from utils import set_state_task
from utils import operation_task
from utils import link_tasks
from utils import CustomContext
from utils import generate_native_node_workflows
from utils import _get_all_nodes
from utils import _get_all_nodes_instances
from utils import _get_all_modified_node_instances
from utils import is_host_node
from workflow import WfStartEvent
from workflow import build_pre_event


#macro(iterateOverSteps $steps)
#foreach($wfStepEntry in ${steps.entrySet()})
#if($util.workflow.isSetStateTask(${wfStepEntry.value}))
    custom_context.add_customized_wf_node('${wfStepEntry.value.activity.nodeId}')
#end
#end
#foreach($wfStepEntry in ${steps.entrySet()})
#if($util.workflow.isSetStateTask(${wfStepEntry.value}))
    set_state_task(ctx, graph, '${wfStepEntry.value.activity.nodeId}', '${wfStepEntry.value.activity.stateName}', '${wfStepEntry.value.name}', custom_context)
#end
#if($util.workflow.isOperationExecutionTask(${wfStepEntry.value}))
    operation_task(ctx, graph, '${wfStepEntry.value.activity.nodeId}', '$util.nonNative.tryToMapToCloudifyInterface(${wfStepEntry.value.activity.interfaceName}).${wfStepEntry.value.activity.operationName}', '${wfStepEntry.value.name}', custom_context)
#end
#if($util.workflow.isDelegateActivityStep(${wfStepEntry.value}))
    custom_context.register_native_delegate_wf_step('${wfStepEntry.value.activity.nodeId}', '${wfStepEntry.value.name}')
#end
#end
#end## macro iterateOverSteps
#macro(buildHostFunctions $stage $steps)
#foreach($wfEntry in ${steps.entrySet()})## foreach 1
#[[#]]# subworkflow '${stage}' for host '${wfEntry.key}'
def ${stage}_host_$util.workflow.getPythonNormalizedString(${wfEntry.key})(ctx, graph, custom_context):
#iterateOverSteps(${wfEntry.value.steps})
    generate_native_node_workflows(ctx, graph, custom_context, '${stage}')
#foreach($internalLink in ${wfEntry.value.internalLinks})## foreach 2
    link_tasks(graph, '${internalLink.toStepId}', '${internalLink.fromStepId}', custom_context)
#end## foreach 2


#end## foreach 1
#end## macro buildHostFunctions
#macro(buildHostLauncher $stage $hosts)
def ${stage}_host(ctx, graph, custom_context, compute):
    options = {}
#foreach($host in ${hosts})## foreach host
    options['${host}'] = ${stage}_host_$util.workflow.getPythonNormalizedString(${host})
#end## foreach host
    options[compute](ctx, graph, custom_context)


#end## macro buildHostLauncher
#buildHostFunctions('install', ${deployment.workflows.installHostWorkflows})
#buildHostFunctions('uninstall', ${deployment.workflows.uninstallHostWorkflows})
#foreach($wfEntry in ${deployment.workflows.standardWorkflows.entrySet()})## standardWorkflows
#buildHostLauncher(${wfEntry.key}, ${wfEntry.value.hosts})
#end## foreach standardWorkflows
#foreach($wfEntry in ${deployment.workflows.workflows.entrySet()})
@workflow
def a4c_${wfEntry.key}(**kwargs):
    graph = ctx.graph_mode()
    nodes = _get_all_nodes(ctx)
    instances = _get_all_nodes_instances(ctx)
    custom_context = CustomContext(ctx, instances, nodes)
    ctx.internal.send_workflow_event(event_type='a4c_workflow_started', message=build_pre_event(WfStartEvent('${wfEntry.key}')))
    _a4c_${wfEntry.key}(ctx, graph, custom_context)
    return graph.execute()


#end
#foreach($wfEntry in ${deployment.workflows.workflows.entrySet()})
def _a4c_${wfEntry.key}(ctx, graph, custom_context):
    #[[#]]#  following code can be pasted in src/test/python/workflows/tasks.py for simulation
#foreach($wfStepEntry in ${wfEntry.value.steps.entrySet()})
#if($util.workflow.isSetStateTask(${wfStepEntry.value}))
    custom_context.add_customized_wf_node('${wfStepEntry.value.activity.nodeId}')
#end## if($util.workflow.isSetStateTask(${wfStepEntry.value}))
#end## foreach($wfStepEntry in ${wfEntry.value.steps.entrySet()})
#foreach($wfStepEntry in ${wfEntry.value.steps.entrySet()})
#if($util.workflow.isSetStateTask(${wfStepEntry.value}))
    set_state_task(ctx, graph, '${wfStepEntry.value.activity.nodeId}', '${wfStepEntry.value.activity.stateName}', '${wfStepEntry.value.name}', custom_context)
#end## if($util.workflow.isSetStateTask(${wfStepEntry.value}))
#if($util.workflow.isOperationExecutionTask(${wfStepEntry.value}))
    operation_task(ctx, graph, '${wfStepEntry.value.activity.nodeId}', '$util.nonNative.tryToMapToCloudifyInterface(${wfStepEntry.value.activity.interfaceName}).${wfStepEntry.value.activity.operationName}', '${wfStepEntry.value.name}', custom_context)
#end## if($util.workflow.isOperationExecutionTask(${wfStepEntry.value}))
#if($util.workflow.isDelegateActivityStep(${wfStepEntry.value}))
    custom_context.register_native_delegate_wf_step('${wfStepEntry.value.activity.nodeId}', '${wfStepEntry.value.name}')
#end## if($util.workflow.isDelegateActivityStep(${wfStepEntry.value}))
#end## foreach($wfStepEntry in ${wfEntry.value.steps.entrySet()})
    generate_native_node_workflows(ctx, graph, custom_context, '${wfEntry.key}')
#foreach($wfStepEntry in ${wfEntry.value.steps.entrySet()})
#foreach($preceding_step in ${wfStepEntry.value.precedingSteps})
    link_tasks(graph, '${wfStepEntry.value.name}', '${preceding_step}', custom_context)
#end## foreach($preceding_step in ${wfStepEntry.value.precedingSteps})
#end## foreach($wfStepEntry in ${wfEntry.value.steps.entrySet()})
#end## foreach($wfEntry in ${deployment.workflows.workflows.entrySet()})

def _get_scaling_group_name_from_node_id(ctx, node_id):
    scaling_groups=ctx.deployment.scaling_groups
    for group_name, scaling_group in ctx.deployment.scaling_groups.iteritems():
        for member in scaling_group['members']:
            if member == node_id:
                ctx.logger.info("Node {} found in scaling group {}".format(node_id, group_name))
                return group_name
    return None

@workflow
def a4c_scale(ctx, node_id, delta, scale_compute, **kwargs):
    delta = int(delta)
    scalable_entity_name = _get_scaling_group_name_from_node_id(ctx, node_id)
    scaling_group = ctx.deployment.scaling_groups.get(scalable_entity_name)
    if scalable_entity_name:
        curr_num_instances = scaling_group['properties']['current_instances']
        planned_num_instances = curr_num_instances + delta
        scale_id = scalable_entity_name
    else:
      scaled_node = ctx.get_node(scalable_entity_name)
      if not scaled_node:
          raise ValueError("Node {0} doesn't exist".format(scalable_entity_name))
      if not is_host_node(scaled_node):
          raise ValueError("Node {0} is not a host. This workflow can only scale hosts".format(scalable_entity_name))
      if delta == 0:
          ctx.logger.info('delta parameter is 0, so no scaling will take place.')
          return
      curr_num_instances = scaled_node.number_of_instances
      planned_num_instances = curr_num_instances + delta
      scale_id = scaled_node.id

    if planned_num_instances < 1:
        raise ValueError('Provided delta: {0} is illegal. current number of'
                         'instances of node/group {1} is {2}'
                         .format(delta, scalable_entity_name, curr_num_instances))

    modification = ctx.deployment.start_modification({
        scale_id: {
            'instances': planned_num_instances
        }
    })
    ctx.logger.info('Deployment modification started. [modification_id={0} : {1}]'.format(modification.id, dir(modification)))
    
    try:
        if delta > 0:
            ctx.logger.info('Scaling host/group {0} adding {1} instances'.format(scalable_entity_name, delta))
            added_and_related = _get_all_nodes(modification.added)
            added = _get_all_modified_node_instances(added_and_related, 'added')
            graph = ctx.graph_mode()
            ctx.internal.send_workflow_event(event_type='a4c_workflow_started',
                                             message=build_pre_event(WfStartEvent('scale', 'install')))
            custom_context = CustomContext(ctx, added, added_and_related)
            install_host(ctx, graph, custom_context, node_id)
            try:
                graph.execute()
            except:
                ctx.logger.error('Scale failed. Uninstalling node/group {0}'.format(scalable_entity_name))
                graph = ctx.internal.task_graph
                for task in graph.tasks_iter():
                    graph.remove_task(task)
                try:
                    custom_context = CustomContext(ctx, added, added_and_related)
                    uninstall_host(ctx, graph, custom_context, scalable_entity_name)
                    graph.execute()
                except:
                    ctx.logger.error('Node {0} uninstallation following scale failure has failed'.format(scalable_entity_name))
                raise
        else:
            ctx.logger.info('Unscaling host/group {0} removing {1} instances'.format(scalable_entity_name, delta))
            removed_and_related = _get_all_nodes(modification.removed)
            removed = _get_all_modified_node_instances(removed_and_related, 'removed')
            graph = ctx.graph_mode()
            ctx.internal.send_workflow_event(event_type='a4c_workflow_started',
                                             message=build_pre_event(WfStartEvent('scale', 'uninstall')))
            custom_context = CustomContext(ctx, removed, removed_and_related)
            uninstall_host(ctx, graph, custom_context, node_id)
            try:
                graph.execute()
            except:
                ctx.logger.error('Unscale failed.')
                raise
    except:
        ctx.logger.warn('Rolling back deployment modification. [modification_id={0}]'.format(modification.id))
        try:
            modification.rollback()
        except:
            ctx.logger.warn('Deployment modification rollback failed. The '
                            'deployment model is most likely in some corrupted'
                            ' state.'
                            '[modification_id={0}]'.format(modification.id))
            raise
        raise
    else:
        try:
            modification.finish()
        except:
            ctx.logger.warn('Deployment modification finish failed. The '
                            'deployment model is most likely in some corrupted'
                            ' state.'
                            '[modification_id={0}]'.format(modification.id))
            raise


@workflow
def a4c_heal(
        ctx,
        node_instance_id,
        diagnose_value='Not provided',
        **kwargs):
    """Reinstalls the whole subgraph of the system topology

    The subgraph consists of all the nodes that are hosted in the
    failing node's compute and the compute itself.
    Additionally it unlinks and establishes appropriate relationships

    :param ctx: cloudify context
    :param node_id: failing node's id
    :param diagnose_value: diagnosed reason of failure
    """

    ctx.logger.info("Starting 'heal' workflow on {0}, Diagnosis: {1}"
                    .format(node_instance_id, diagnose_value))
    failing_node = ctx.get_node_instance(node_instance_id)
    host_instance_id = failing_node._node_instance.host_id
    failing_node_host = ctx.get_node_instance(host_instance_id)
    node_id = failing_node_host.node_id
    subgraph_node_instances = failing_node_host.get_contained_subgraph()
    added_and_related = _get_all_nodes(ctx)
    try:
      graph = ctx.graph_mode()
      ctx.internal.send_workflow_event(event_type='a4c_workflow_started',
                                               message=build_pre_event(WfStartEvent('heal', 'uninstall')))
      custom_context = CustomContext(ctx, subgraph_node_instances, added_and_related)
      uninstall_host(ctx, graph, custom_context, node_id)
      graph.execute()
    except:
      ctx.logger.error('Uninstall while healing failed.')
    graph = ctx.internal.task_graph
    for task in graph.tasks_iter():
      graph.remove_task(task)
    ctx.internal.send_workflow_event(event_type='a4c_workflow_started',
                                             message=build_pre_event(WfStartEvent('heal', 'install')))
    custom_context = CustomContext(ctx, subgraph_node_instances, added_and_related)
    install_host(ctx, graph, custom_context, node_id)
    graph.execute()

#[[#]]#following code can be pasted in src/test/python/workflows/context.py for simulation
#[[#]]#def _build_nodes(ctx):
#foreach($nodeEntry in ${deployment.allNodes.entrySet()})
    #[[#]]#types = []
    #[[#]]#types.append('${nodeEntry.value.nodeTemplate.type}')
#foreach($nodeType in ${nodeEntry.value.indexedToscaElement.derivedFrom})
    #[[#]]#types.append('${nodeType}')
#end
    #[[#]]#node_${nodeEntry.key} = _build_node(ctx, '${nodeEntry.key}', types, 1)
#end
#foreach($nodeEntry in ${deployment.allNodes.entrySet()})
#foreach($relationshipEntry in ${nodeEntry.value.nodeTemplate.relationships.entrySet()})
    #[[#]]#_add_relationship(node_${nodeEntry.key}, node_${relationshipEntry.value.target})
#end
#end
